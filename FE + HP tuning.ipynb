{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULFILLEMENT_CENTER = 'input/fulfilment_center_info.csv'\n",
    "MEAL_INFO = 'input/meal_info.csv'\n",
    "TRAIN = 'input/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = 'input/test.csv'\n",
    "SAMPLE_SUBMISSION = 'input/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN)\n",
    "meal_df = pd.read_csv(MEAL_INFO)\n",
    "fulfillement_center_df = pd.read_csv(FULFILLEMENT_CENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging \n",
    "\n",
    "tmp_df = pd.merge(df, meal_df, how='left', on='meal_id')\n",
    "df = pd.merge(tmp_df, fulfillement_center_df, how='left', on='center_id')\n",
    "\n",
    "test_df = pd.merge(test_df, meal_df, how='left', on=\"meal_id\")\n",
    "test_df = pd.merge(test_df, fulfillement_center_df, how='left', on='center_id')\n",
    "\n",
    "del tmp_df, fulfillement_center_df, meal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature engineering</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_features(df):\n",
    "    df[\"base_over_checkout\"] = df['base_price'] / df['checkout_price']\n",
    "    df['center_meal_id'] = df['center_id'].astype(str) + '_' + df['meal_id'].astype(str)\n",
    "    df['prom+homepage'] = df['emailer_for_promotion'].astype(str) + '_' + df['homepage_featured'].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagging_features(df):\n",
    "    \n",
    "    windows = [2, 4, 15, 30, 52]\n",
    "    \n",
    "    for w in windows:  \n",
    "        print(f'Generating features with {w}-week time frame')\n",
    "        \n",
    "        df[f'avg_past_checkout_price_{w}'] = df.groupby(['center_id', 'meal_id'])['checkout_price'].shift(w-1).rolling(w).mean()\n",
    "        df[f'avg_past_base_price_{w}'] = df.groupby(['center_id', 'meal_id'])['base_price'].shift(w-1).rolling(w).mean()\n",
    "\n",
    "        df[f'std_past_checkout_price_{w}'] = df.groupby(['center_id', 'meal_id'])['checkout_price'].shift(w-1).rolling(w).std()\n",
    "        df[f'std_past_base_price_{w}'] = df.groupby(['center_id', 'meal_id'])['base_price'].shift(w-1).rolling(w).std()\n",
    "        \n",
    "        df[f'min_past_checkout_price_{w}'] = df.groupby(['center_id', 'meal_id'])['checkout_price'].shift(w-1).rolling(w).min()\n",
    "        df[f'min_past_base_price_{w}'] = df.groupby(['center_id', 'meal_id'])['base_price'].shift(w-1).rolling(w).min()\n",
    "        \n",
    "        df[f'max_past_checkout_price_{w}'] = df.groupby(['center_id', 'meal_id'])['checkout_price'].shift(w-1).rolling(w).max()\n",
    "        df[f'max_past_base_price_{w}'] = df.groupby(['center_id', 'meal_id'])['base_price'].shift(w-1).rolling(w).max()\n",
    "        \n",
    "        df[f'has_been_promoted_{w}'] = df.groupby(['meal_id'])['emailer_for_promotion'].shift(w-1).rolling(w).sum()\n",
    "        df[f'has_been_featured_{w}'] = df.groupby(['meal_id'])['homepage_featured'].shift(w-1).rolling(w).sum()\n",
    "        \n",
    "        df[f'avg_num_orders_lag_{w}'] = df.groupby(['center_id', 'meal_id'])['num_orders'].shift(w-1).rolling(w).mean()\n",
    "        df[f'std_num_orders_lag_{w}'] = df.groupby(['center_id', 'meal_id'])['num_orders'].shift(w-1).rolling(w).std()\n",
    "        df[f'min_num_orders_lag_{w}'] = df.groupby(['center_id', 'meal_id'])['num_orders'].shift(w-1).rolling(w).min()\n",
    "        df[f'max_num_orders_lag_{w}'] = df.groupby(['center_id', 'meal_id'])['num_orders'].shift(w-1).rolling(w).max()\n",
    "        \n",
    "        df[f'num_orders_lag_{w}'] = df.groupby(['center_id', 'meal_id'])['num_orders'].shift(w)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lagging_features(df)\n",
    "test_df = lagging_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = interaction_features(df)\n",
    "test_df = interaction_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df):\n",
    "    cat_var = ['category', 'cuisine', 'center_type', 'center_meal_id', 'prom+homepage']\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for c in cat_var:\n",
    "        df[c] = le.fit_transform(df[c])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_categorical_features(df)\n",
    "test_df = encode_categorical_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modelling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))) * 100, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['num_orders']\n",
    "y = np.log1p(y)\n",
    "X = df.drop(['id', 'num_orders'], axis=1)\n",
    "\n",
    "X_test = test_df.drop(['id', 'num_orders'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quich check\n",
    "\n",
    "assert((X.columns == X_test.columns).all()), 'columns are not the same'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "test_preds = []\n",
    "\n",
    "for train_index, valid_index in tscv.split(X, y):\n",
    "    X_train = X.loc[train_index].values\n",
    "    X_valid = X.loc[valid_index].values\n",
    "    \n",
    "    y_train = y.loc[train_index].values\n",
    "    y_valid = y.loc[valid_index].values\n",
    "        \n",
    "    gbm = xgb.XGBRegressor()\n",
    "    \n",
    "    gbm.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric='mae', early_stopping_rounds=5, verbose=20)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Evaluating model...\")\n",
    "    y_pred = gbm.predict(X_valid)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    \n",
    "    y_valid = np.expm1(y_valid)\n",
    "    metric = rmsle(y_valid, y_pred)[1]\n",
    "    metrics.append(metric)\n",
    "    print('The rmsle of prediction is:', metric)\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Predicting test set...')\n",
    "    y_pred = gbm.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    test_preds.append(y_pred)\n",
    "    print('\\n')\n",
    "\n",
    "print('Evaluation RMLSE: {}'.format(np.mean(np.array(metrics))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Experiment summary</h3>\n",
    "\n",
    "No feature engineering / baseline: **98**<br/>\n",
    "Slight feature engineering: **96.8**<br/>\n",
    "Slight feature engineering + log target: **68.2**<br/>\n",
    "Lag feature engineering + log target: **67.1**<br/>\n",
    "Enhanced feature engineering + log target: **60.14**<br/>\n",
    "Final feature engineering + log target: **54.6**<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = np.mean(test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Inference</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['num_orders']  = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(SAMPLE_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
